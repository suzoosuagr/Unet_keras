{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from data import *\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_images(image_path, num_imagees=10, image_size=(256,256)):\n",
    "    while True:\n",
    "        assert os.path.isdir(image_path), 'Could not find {}'.format(image_path)\n",
    "        filenames = [os.path.join(image_path, f) for f in os.listdir(image_path)if f.endswith('.jpg')]\n",
    "        print(len(filenames))\n",
    "        for i, f in enumerate(filenames):\n",
    "            if i < num_imagees:\n",
    "                img = io.imread(f)\n",
    "                img = img/255\n",
    "                img = trans.resize(img,image_size)\n",
    "                img = np.reshape(img, (1,) + img.shape)\n",
    "                yield img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../data/Training/ISIC2018_256_256_input/test'\n",
    "images = get_test_images(test_dir, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwang/jwang/Unet_keras/model.py:69: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n",
      "  model = Model(input = inputs, output = conv10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = unet()\n",
    "model.load_weights('unet_ori.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260\n",
      "260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwang/jwang/deep-learning-server/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/jwang/jwang/deep-learning-server/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/10 [====================>.........] - ETA: 0s260\n",
      "10/10 [==============================] - 0s 47ms/step\n"
     ]
    }
   ],
   "source": [
    "results = model.predict_generator(images, 10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "for i, img in enumerate(results):\n",
    "    img = np.reshape(img,(256,256))\n",
    "    img = (img > 0.1) * 255\n",
    "    fig.add_subplot(3,4,i+1)\n",
    "    plt.imshow(img, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25742856\n"
     ]
    }
   ],
   "source": [
    "pick = results[3]\n",
    "print(pick.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "myGene = trainGenerator(2,'membrane/train','image','label',data_gen_args,save_to_dir = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n",
      "(2, 256, 256, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-bb2fecb957a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmyGene\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jwang/Unet_keras/data.py\u001b[0m in \u001b[0;36mtrainGenerator\u001b[0;34m(batch_size, train_path, image_folder, mask_folder, aug_dict, mask_color_mode, image_save_prefix, mask_save_prefix, flag_multi_class, num_class, save_to_dir, target_size, seed)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0msave_prefix\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmask_save_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         seed = seed)\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madjustData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflag_multi_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jwang/deep-learning-server/lib/python3.6/site-packages/keras_preprocessing/image.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1526\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jwang/deep-learning-server/lib/python3.6/site-packages/keras_preprocessing/image.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1968\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1970\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jwang/deep-learning-server/lib/python3.6/site-packages/keras_preprocessing/image.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m   1928\u001b[0m                 \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1929\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_random_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1930\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1931\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1932\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jwang/deep-learning-server/lib/python3.6/site-packages/keras_preprocessing/image.py\u001b[0m in \u001b[0;36mapply_transform\u001b[0;34m(self, x, transform_parameters)\u001b[0m\n\u001b[1;32m   1286\u001b[0m                                    \u001b[0mchannel_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_channel_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m                                    \u001b[0mfill_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m                                    cval=self.cval)\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransform_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'channel_shift_intensity'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jwang/deep-learning-server/lib/python3.6/site-packages/keras_preprocessing/image.py\u001b[0m in \u001b[0;36mapply_affine_transform\u001b[0;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval)\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             cval=cval) for x_channel in x]\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_axis\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jwang/deep-learning-server/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0msl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0mexpanded_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for img,mask in myGene:\n",
    "    print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
